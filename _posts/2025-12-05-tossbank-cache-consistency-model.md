---
layout: post
title: "That's not strong consistency cache architecture"
slug: tossbank-strong-cache
category: essay
---

## urge to write this article

회사에서 이야기를 나누다가 어떤 아티클을 공유받았습니다. 토스뱅크에서 작성한 캐시에 대한 글이었고,
꽤나 어려워보이는 개념들을 이야기하면서 멋진 시스템 개선 방식을 소개하고있어서 즐겁게 읽었습니다. 
한편으로는 분산 시스템에서의 strong consistency를 적용하는 방식이 꽤나 특이하다는 느낌도 받았습니다. 
읽다보니 점점 엄밀한 잣대로 글을 읽게 되더군요. 제 안의 분산시스템 악마가 깨어나고 있었습니다.
이렇게 간단히 성능 저하 없이 문제글 잘 해결하는게 불가능하다는 생각이 들면서 몇가지 반례를 찾아내었습니다.
이미 저 글의 표현이 잘못되었다는건 확인했지만, 단순히 트집잡기에 불과하여 글을 약 반년간 방치했는데요.
이번에 저도 분산 시스템의 안정성을 검증해야하는 일이 생겨서 좋은 훈련으로 사용해보았습니다.

> 멋진 캐시 적용 아티클을 비난하고싶은 마음은 없습니다. 토스 뱅크의 기술력은 뛰어나다고 생각하며,
> 매우 거대한 시스템을 안정적으로 운영하는 몇 안되는 은행입니다. 저의 전세 대출도 여기서 받았습니다 ;>

## 아티클을 요약하자면

약관 데이터 서빙을 leader DB(아마 RDBMS겠죠?)에서만 수행하고 있었습니다. 이는 '강한 일관성;'이라고 하는 속성을 지키기 위함이라고 합니다.
요청이 점점 늘어나감에 따라서 단일 DB 인스턴스로는 성능 한계에 도달하게 됩니다.
따라서 빠르게 읽기를 할 수 있는 캐시 레이어를 도입합니다. 이때 redis를 캐시 저장소로 선택하고,
write시에 cache evict, read시에 cache를 채우는 방식으로 구현을 합니다.
일관성이 매우 중요하기 때문에 Kafka 이벤트 발행 순서도 조절하고, redis에 대하여 서킷도 달았습니다.

write시에 cache evict하는 타이밍은 db에 commit이 된 다음 application server에서 redis unlink를 수행하고, 성공적으로 redis unlink가 수행되면 API의 응답을 주게 됩니다.

## 일관성 모델

원 불로그에서는 처음에 강한 일관성(Strong Consistency, 혹은 Linearizability)을 의도하고 시스템을 만들다가 후반부에는 비교적 약한 일관성을 가진 시스템으로 타협하게 됩니다.

| "약관 동의 또는 철회 요청 API 처리가 완료된 순간, 바로 다음 요청에 DB에 저장된 값이 응답되어야 한다"

이게 우리의 요구사항입니다. API의 처리가 완료되었다면 그 다음 요청에서 DB의 값이 응답된다. 정확히 어떠한 속성인지 해석의 여지가 있으니 조금 더 너그러운 일관성 모델로 생각해보겠습니다. 바로 Read Your Writes입니다. 

**Read-Your-Writes**: 사용자가 성공적으로 쓰기를 완료한 후, 그 사용자의 다음 읽기 요청은 반드시 그 쓰기 내용을 포함한 최신 값을 반환해야 합니다.

RYW(Read Your Writes)의 경우에 세션의 일관성 모델인데, 세션의 인과관계가 역전되는 일을 방지합니다. 물론 동일 세션이 아닌 다른 세션을 기준으로도 역전이 일어나게 됩니다.

Monotonic Read(No-Flickering)과 같은 속성은 지금은 무시하도록합니다.

## 반례를 발견하는 것의 어려움

분산 시스템의 안전성, 혹은 특정 속성을 보장하지 않는 다는 것은 비교적 쉽게 찾을 수 있습니다. 단 한가지 반례를 찾으면 우리의 모델이 틀렸다는 것을 검증할 수 있습니다. 하지만 반례가 없다는 것을 증명하는 것은 조금 더 까다롭습니다. 모든 조합이 아주 적은 수의 조건에 따라서 지수적으로 증가합니다. 동시에 실행되는 프로세스가 2개로 늘어나면 상황은 4가지가 됩니다. 프로세스가 3개가 되면 더욱 많이 늘어나겠지요. 게다가 끝없이 실행되는 프로그램이라면 어떨까요? 아주 우연히 특정 순서대로 프로그램이 수행된다면, 우리는 그 상황을 검토할 수 있을까요? 아마 불가능할겁니다. 개발자의 두뇌는 그렇게 동작하지 않습니다.

그렇기에 반례를 찾는 상황은 온전히 개발자의 상상력과, 경험에 의존합니다. 이건 문제가 있을 것 같다는 직관, 비슷한 문제를 풀어보았던 경험이 많이 작용하죠.
호기심이 많은 개발자가 이 상황, 저 상황 탐색하면서 문제를 찾을 수도 있습니다. 또, 분산 시스템에 익숙한 사람이라면 특정 정합성을 만족하기 위한 최소 조건을 증명하고, 이 시스템이 충분조건을 만족하고 있다는 것을 증명할 수도 있습니다.

저는 이런 시스템에 관심이 많기에 글을 읽자마다 반례가 바로 떠올랐습니다. 그리고 최소 조건을 감으로 알고있기에 원문에서 제안한 내용이 최소조건을 충분히 기술하지 않다는 것도 느꼈습니다. 모두가 이런게 가능하지 않습니다. 아주 익숙한 사람이더라도 시간을 들여 천천히 생각하지 않으면 문제를 놓칠 수 있습니다.

## TLA+ Spec으로 모델 정의하여 검증하기

저는 이번 검증에서 TLA+를 사용하겠습니다. 언급했다시피 단순한 반례 몇가지를 찾는 것은 매우 쉽지만, 개개인의 상상력에 의존합니다.
개발자 한명이 생각할 수 있는 시나리오는 고작해야 한번에 20가지가 전부이고, 수천만건이 있는 상황을 빠짐없이 시뮬레이션하는 것은 불가능하죠. 이는 컴퓨터가 잘 하는 것입니다. 
어떤 컴포넌트의 문제가 있다는 것을 잘 드러낼 수 있는 방법인 Formal Method를 사용하여 모델링을 시작해보겠습니다.

유저는 한명이지만, 동시에 여러 요청을 보낼 수 있다고 가정하겠습니다.
App에서 요청을 보내는 경우 단 하나의 요청만 보내는 경우는 거의 없기도하고, 서버 안에서 요청이 퍼지면서 여러 요청으로 퍼지면서 비슷한 요청이 동시에 들어올 수도 있습니다.
아주 단순한 user -> server -> db & redis 모델입니다. 각 컴포넌트 간의 통신은 network로 통신하며 순서가 바뀔 수 있습니다. 물론 tcp 기반으로 생각하고있기에 커넥션 단위의 메시지 순서가 바뀌지 않습니다. 네트워크는 유실도 일어나지 않습니다.

단순한 쓰기 & 읽기 시나리오입니다.

![읽기 시나리오](https://github.com/MagicalLas/MagicalLas.github.io/blob/master/_screenshots/read-seq.svg?raw=true)
![쓰기 시나리오](https://github.com/MagicalLas/MagicalLas.github.io/blob/master/_screenshots/write-seq.svg?raw=true)

강한 일관성이라면 이러한 문제에서 자유롭겠지요. 하지만 우리는 그정도로 원하지 않으니 단 하나의 속성만 체크하겠습니다. 
동일한 유저의 요청 스레드라면 자신이 write에 성공한 이후에 새로 시작하는 read에서는 write가 반영되어야한다는 것입니다.

```tla
ReadYourWriteConsistency ==
    \A u \in Users:
        clientView[u] # NoneVal =>
            clientView[u].version >= lastWriteVersion[u]
```

아래와 같이 Read와 Write의 시퀀스가 만들어집니다. 모든 network은 지연이 있을 수 있지만, 단일 커넥션에 대하여 순서가 바뀌는 일은 없습니다. 또한 유실이 없고, 모든 요청은 실패하는 일이 없습니다. 실제로는 실패하는 경우도 있기에 더 상황이 복잡해집니다.

## 반례

```d2
shape: sequence_diagram

u1: "User 1"
u2: "User 2"
s1: "Server 1"
s2: "Server 2"
redis: "Redis"
db: "Database"

db.v=1

u1 -> s1: ReadReqeust
s1 -> redis: Get
s1 <- redis: Missed

s1 -> db: Select
s1 <- db: Result(v=1)

u2 -> s2: WriteReqeust
s2 -> db: Update
db -> db: (v' = v+1)
s2 <- db: Result(v=2)
s2 -> redis: Unlink
u2 <- s2: WriteRseponse(v=2)

u2.lastSeen = "v=2"

s1 -> redis: Set(v=1)
redis.value = "v=1"
s1 <- redis: SetOk

u1 <- s1: ReadResponse(v=1)

u2 -> s1: ReadReqeust
s1 -> redis: Get
s1 <- redis: Hit(v=1)
u2 <- s1: ReadResponse(v1)
```

이렇게 단순한 모델, 그리고 네트워크 지연만 있는 경우에도 문제는 발생합니다. 문제가 되는 시퀀스를 하나 보여드리겠습니다. Set이 지연해서 도착하면서 unlink가 되었지만 기존값으로 캐시가 채워진 모습입니다. 단일 요청 흐름에서 보더라도 동시에 2가지 요청이 수행되는 경우 실제로 write가 성공했지만 이전값이 나온다는 점입니다. 자신의 쓰기가 무시된 상태죠.

이 시나리오에서 토스뱅크가 주장하는 "약관 동의 여부는 약관 동의 또는 철회 요청 API 처리가 완료된 순간, 바로 다음 요청에 DB에 저장된 값이 응답되어야 한다."에 정면으로 위배되는 케이스이죠.  Write 요청이 다시 발생하거나, TTL이 지나지 않는다면 계속해서 이전값을 보게 됩니다. 심지어 Write 요청이 DB에 commit되었고, 성공으로 응답이 내려온 상태죠. DB에 저장된 값이 아닌, 자신이 쓴 값도 내려오지 않는겁니다.

네트워크 지연을 가정하는게 합리적이지 않을 수도 있습니다. 아주 적을 확률일 수 있습니다. 하지만 실제로 발생할 수 있는 경우입니다. network rtt, gc 지연등을 짧게 잡더라도 분산시스템간의 atomic하지 않은 순간에 대하여 끼어들 수 있는 상황은 매일 생깁니다. 아주 조금의 순간이더라도 요청마다 계속해서 수행되다보면 언젠가 발생하는 경우도 있을겁니다.

발생하지 않게 만드려면 지금의 구조로는 부족합니다. 추가적인 매커니즘이 필요해요.

## 서킷브레이커는 도움이 되지 않는다

그리고 그 메커니즘은 분명히 서킷브레이커가 아닙니다. 저는 서킷브레이커를 아예 모델에 넣지도 않았는데요, 이는 redis 호출이 항상 성공하기 때문입니다. 위의 반례의 경우 unlink가 항상 성공하고있습니다.
서킷 브레이커가 열리지 않고도 정합성 문제가 몇분이상 지속될 수 있다는걸 볼 수 있죠. 애초에 서킷브레이커는 문제 발생시의 차단 역할입니다. 근본적인 시스템의 허점을 막아주지 않습니다.

물론 서킷이 있다는 것은 실용적인 접근이고, 저는 서킷을 좋아합니다. 장애 차단 관점에서 얼마나 중요한지 잘 알고있습니다 ;)

## Unlink를 DB Transaction안에서 수행하는건 도움이 되지 않는다

몇가지 변형을 가하면, 단순한 수정으로 이런 일관성 속성을 개선할 수 있을까요? 지금은 AFTER_COMMIT으로 DB에 커밋한 다음 redis에서 unlink를 수행합니다. 만약 Transaction commit 전에 unlink를 한다면 어떻게 될까요?

여전히 동일한 문제는 남습니다.

```
```

(1)DB Commit -> Unlink와 (2)Read Path에서의 DB Read->Set간의 순서 불일치가 현상의 원인입니다. 1번과 2번이 각각 Atomic하지 않기에 DB에서의 순서는 존재하지만 Redis에서의 순서는 DB의 순서와 달라지기 때문입니다.

혹시 너무나 마법적인 일이 일어나서 DB에 commit하는 순간 redis도 unlink가 일어난다면 어떻게 될까요? 동일하게 TLA+로 모델링해보겠습니다.

```
```

그래도 여전히 동일한 문제가 남습니다. 이는 ~~ 때문입니다. 1번이 Atomic하더라도 2번이 Atomic하지 않으면, 혹은 2번의 순서가 바뀌어서 수행될 수 있다면 문제가 존재합니다.

## redis SET NX를 사용해도 도움이 되지 않는다

혹시 Read시에 보통 SET NX를 자주 사용해서 캐시를 채우는데 효과가 있을까요? 없습니다. 1번이 Atomic하게 되었고, 2번의 Atomic이나 순서 보장이 필요한데 SET NX는 둘 다 만족하지 못하기 때문이죠.

## Write에서도 Cache를 채우도록 해도 도움이 되지 않는다

Read할 때 캐시를 채우는 경우 여러가지 방법을 넣어도 크게 도움이 되지 않네요. 이제 Write를 같이 살펴봐야겠습니다. Read가 아니라 Write에서 SET을 수행하는겁니다.

commit이 되지 않은 데이터를 set을 할 수는 없으니 commit된 이후에 SET을 수행하도록합니다. Read에서 SET NX를 사용하면서 Write Path에서 SET NX는 사용하지 않습니다. Read Path에서 Write Path의 SET을 무시하고싶지는 않을테니까요. (문제가 된다는걸 TLA+로 검증했지만, 귀찮음으로인해 서술하지 않습니다)

여전히 동일한 문제가 존재합니다.

## Write에서만 Cache를 채우도록 해도 도움이 되지 않는다

Read에서 채우지않고, Write시에만 채우게하면 문제가 없을까요? 아뇨, 여전히 문제가 있습니다.

지금까지 몇가지 생각나는, 흔히 시도하는 방법들에 대하여 시도해보았지만 문제가 사라지지 않았습니다.

## 대안 1 - lock

문제는 DB Commit과 Redis SET이 원자적이지 않다는 것입니다. 이를 원자적으로 만들면 문제가 해결됩니다.

약관의 경우 Read Heavy한 패턴이기에 합리적인 방법입니다. 이 방법의 경우 Read에서 SET NX를 쓰고, Write시에 Lock으로 순서를 엄밀히 보장하면 적어도 "Read Your Writes"는 보장합니다.

Write에만 Lock을 잡는 것은 Monotonic Read를 만족할 수는 없지만, 중요한 속성은 아닐 수 있습니다.

## 대안 2 - logical clocks

CAS처럼 redis에서 version을 확인해서 이전 버전에 대한 SET (NX)를 무시하는 것입니다. 이것도 Monotonic Read는 만족하지 못하지만, "Read Your Writes"를 만족하게 됩니다.

## 마무리

분산시스템은 직관으로 이해하기 어렵습니다. 개발자의 상상력과 사고력은 한계가 있고, 유명한 오픈소스들도 오류를 범하기도합니다.
자신있게 안전하다고 생각한 속성도 실제로 지켜지지 못할 수도 있습니다.

추상적인 모델을 검증할 수 있는 Formal Method를 사용해서 캐시 시스템의 일관성을 모델링하고 검증해보았습니다. 
작은 노력으로 사람이 상상할 수 없는 조합을 검증하면서 우리의 시스템을 더 잘 이해할 수 있습니다.
Unlink에서 SET, SET NX, Lock등의 방법들을 쉽게 전환하면서 검증하며 시스템을 견고하게 디자인해나갈 수 있습니다.

안전한, 정확한 시스템을 구현하기 위한 이야기를 나누고싶으신 분이 있다면 편히 메일주세요!
